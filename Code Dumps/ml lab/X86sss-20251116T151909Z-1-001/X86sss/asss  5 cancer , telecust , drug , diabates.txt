asss  5

1. Perform logistic regression to classify if a patient has a benign tumor or malignant
tumor (cancer) based on the features provided. Generate the confusion matrix and

evaluate the quality of the model by computing relevant performance metrics in-
cluding Precision, Recall, accuracy, F1-Score etc. Plot the ROC curve and calculate

AUC. Dataset: samplescancer.csv


# Logistic Regression - Cancer Classification
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    confusion_matrix, classification_report, roc_curve, auc, accuracy_score
)
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv("samples_cancer.csv")

# Check column names
print("Columns in dataset:", df.columns.tolist())

# Encode target (Class: 2 = benign, 4 = malignant)
# Convert to binary (0 = benign, 1 = malignant)
df['Class'] = df['Class'].map({2: 0, 4: 1})

# Handle missing values (if any 'BareNuc' are '?')
df = df.replace('?', pd.NA)
df = df.dropna()
df['BareNuc'] = df['BareNuc'].astype(int)

# Features and target
X = df.drop(['ID', 'Class'], axis=1)
y = df['Class']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train logistic regression
model = LogisticRegression(max_iter=2000)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

# Metrics
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))

# ROC curve
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}")
plt.plot([0,1], [0,1], linestyle='--')
plt.title("ROC Curve - Logistic Regression (Cancer)")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()


////////////////////////////////////////////////////////////////////////


2. Using KNN algorithm, predict which category a customer belongs to based on the

data provided by a telecommunications firm. Find the accuracy of the KNN algo-
rithm in predicting the category of a customer. Dataset: teleCust.csv




# KNN - Telecom Customer Classification
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv("teleCust.csv")

# Assuming target column is 'custcat'
le = LabelEncoder()
df['custcat'] = le.fit_transform(df['custcat'])

X = df.drop('custcat', axis=1)
y = df['custcat']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Scale data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# Predict
y_pred = knn.predict(X_test)

# Accuracy
print("KNN Accuracy:", accuracy_score(y_test, y_pred))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion matrix heatmap
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix - KNN (Telecom)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()



//////////////////////////////////////////////////////////////////

3. Using the Decision Tree algorithm, predict which drug among drug X, drug Y, and
drug C should be given to a patient. Find the accuracy of the decision tree in
predicting the correct drug for the patient. Dataset: drug.csv




# Decision Tree - Drug Prediction
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv("drug.csv")

# Encode categorical features
le = LabelEncoder()
for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = le.fit_transform(df[col])

# Split data
X = df.drop('Drug', axis=1)
y = df['Drug']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Train Decision Tree
dt = DecisionTreeClassifier(criterion="entropy", random_state=42)
dt.fit(X_train, y_train)

# Predict
y_pred = dt.predict(X_test)

# Metrics
print("Decision Tree Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Plot tree (top few levels)
plt.figure(figsize=(12,8))
plot_tree(dt, feature_names=X.columns, class_names=[str(c) for c in set(y)], filled=True, max_depth=3)
plt.show()

# Confusion matrix heatmap
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Greens')
plt.title("Confusion Matrix - Decision Tree (Drug)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()





//////////////////////////////////////////////////////////


4. Using Naive Bayes algorithms, predict if a person is diabetic or not, based on the
features provided. Find the accuracy and F1-Scores of both algorithms.

# Naive Bayes - Diabetes Prediction
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB, BernoulliNB
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset (no headers in this file)
column_names = [
    "Pregnancies", "Glucose", "BloodPressure", "SkinThickness",
    "Insulin", "BMI", "DiabetesPedigreeFunction", "Age", "Outcome"
]
df = pd.read_csv("pima-indians-diabetes.data.csv", header=None, names=column_names)

# Features and target
X = df.drop('Outcome', axis=1)
y = df['Outcome']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Gaussian Naive Bayes
gnb = GaussianNB()
gnb.fit(X_train, y_train)
y_pred_gnb = gnb.predict(X_test)

# Bernoulli Naive Bayes
bnb = BernoulliNB()
bnb.fit(X_train > 0, y_train)
y_pred_bnb = bnb.predict(X_test > 0)

# GaussianNB metrics
print("\n--- Gaussian Naive Bayes ---")
print("Accuracy:", accuracy_score(y_test, y_pred_gnb))
print("F1 Score:", f1_score(y_test, y_pred_gnb))
print(classification_report(y_test, y_pred_gnb))

# BernoulliNB metrics
print("\n--- Bernoulli Naive Bayes ---")
print("Accuracy:", accuracy_score(y_test, y_pred_bnb))
print("F1 Score:", f1_score(y_test, y_pred_bnb))
print(classification_report(y_test, y_pred_bnb))

# Confusion matrices
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
sns.heatmap(confusion_matrix(y_test, y_pred_gnb), annot=True, fmt='d', cmap='Blues')
plt.title("GaussianNB Confusion Matrix")

plt.subplot(1,2,2)
sns.heatmap(confusion_matrix(y_test, y_pred_bnb), annot=True, fmt='d', cmap='Oranges')
plt.title("BernoulliNB Confusion Matrix")
plt.show()
